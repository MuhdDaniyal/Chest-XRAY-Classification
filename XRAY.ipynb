{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the data directly from kaggle\n",
    "os.environ['KAGGLE_USERNAME'] = \"muhddaniyal\"\n",
    "os.environ['KAGGLE_KEY'] = \"ced0131dac41051a559103b16031f513\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download tawsifurrahman/covid19-radiography-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we've got the zip folder from the above cell so now we've to unzip it\n",
    "!unzip covid19-radiography-database.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = pd.read_excel('/content/COVID-19_Radiography_Dataset/Normal.metadata.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.head()\n",
    "# We've paths of every image in the COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're selecting the covid and normal folder we can also choose other but right now we're working on the\n",
    "# COVID and Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('/content/COVID-19_Radiography_Dataset/COVID/'))\n",
    "# We've two folders inside the COVID folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('/content/COVID-19_Radiography_Dataset/COVID/images/'))\n",
    "# no. of images we've in the covid folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('/content/COVID-19_Radiography_Dataset/Normal/'))\n",
    "# We've two folders inside the Normal folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('/content/COVID-19_Radiography_Dataset/Normal/images/'))\n",
    "# no. of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normal_count = len(os.listdir('/content/COVID-19_Radiography_Dataset/Normal/images/'))\n",
    "covid_count = len(os.listdir('/content/COVID-19_Radiography_Dataset/COVID/images/'))\n",
    "\n",
    "data = {'Class': ['Normal', 'Covid'], 'Count': [normal_count, covid_count]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Class', y='Count', data=df, palette = ['#77C3EC', 'red'])\n",
    "\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Dataset Balance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we detected the problem here that training data is not balanced right now\n",
    "# Imbalanced dataset usually have low accuracy or biased data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading any one image using cv2\n",
    "img = cv2.imread('/content/COVID-19_Radiography_Dataset/Normal/images/Normal-10074.png')\n",
    "sns.set(style=\"white\")\n",
    "plt.axis('off')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension of the image\n",
    "print('Image Shape: {}'.format(img.shape))\n",
    "print('Image Height: {}'.format(img.shape[0]))\n",
    "print('Image Width: {}'.format(img.shape[1]))\n",
    "print('Image Dimension: {}'.format(img.ndim))\n",
    "print('Image Size: {}kb'.format(img.size//1024))\n",
    "print('Image Data Type: {}'.format(img.dtype))\n",
    "print('Maximum RGB value of the image: {}'.format(img.max()))\n",
    "print('Minimum RGB value of the image: {}'.format(img.min()))\n",
    "# We don't want to resize the images because all the images in the dataset is 299*299 pixels mentioned\n",
    "# in the description at kaggle where the datset is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also observe that the image has 3 channels, hence it in in RGB scale even if these are X-ray images.\n",
    "plt.title('B channel', fontsize = 14)\n",
    "plt.imshow(img[ : , : , 0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path, urls, target):\n",
    "  images = []\n",
    "  labels = []\n",
    "  for i in range(len(urls)):\n",
    "    img_path = path + \"/\" + urls[i]\n",
    "    img = cv2.imread(img_path)\n",
    "    img = img / 255.0\n",
    "    #print(img_path)\n",
    "    # if we want to resize the images\n",
    "    img = cv2.resize(img, (100, 100)) # runtime crashing again and again\n",
    "    images.append(img)\n",
    "    labels.append(target)\n",
    "  images = np.asarray(images)\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_path = \"COVID-19_Radiography_Dataset/COVID/images\"\n",
    "covidUrl = os.listdir(covid_path)\n",
    "covidImages, covidTargets = loadImages(covid_path, covidUrl, 1) # 1 is -ve class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(covidUrl), len(covidImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_path = \"COVID-19_Radiography_Dataset/Normal/images\"\n",
    "normal_urls = os.listdir(normal_path)\n",
    "normalImages, normalTargets = loadImages(normal_path, normal_urls, 0) # 0 is +ve class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normal_urls), len(normalImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returning a list so I cannot use as an array so we've to typecast it into array\n",
    "# Why? because we cannot directly reshape the data, we cannot divide the data by 255 to normalize the images\n",
    "\n",
    "# covidImages = np.asarray(covidImages)\n",
    "# normalImages = np.asarray(normalImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covidImages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalImages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the data row wise\n",
    "data = np.r_[covidImages, normalImages]\n",
    "targets = np.r_[covidTargets, normalTargets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data/255.0\n",
    "# failed to do this because I don't have much RAM because data is too large\n",
    "# runtime disconnected\n",
    "# 1st solution is resizing the image\n",
    "# Second solution is Keras. It fetches the data in bathces we don't even have to write code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, targets, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, 3, input_shape=(100,100,3), activation='relu'),\n",
    "    MaxPooling2D(),                     #set to default pool_size, strides, padding, etc\n",
    "    Conv2D(16, 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(16, 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# keras.layers.Conv2D(\n",
    "#     filters,\n",
    "#     kernel_size,\n",
    "#     input_shape,\n",
    "#     activation=None,      we generally uses relu becuase it removes -ve values if it is multiplied with filter or something\n",
    "#     padding is valid by default\n",
    "# )\n",
    "# Flatten() will create input layer that contains all my neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,batch_size=32,epochs=5,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
